{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c8cd207-b284-49ec-8ae1-08504d76b8a7",
   "metadata": {},
   "source": [
    "# Upload\n",
    "\n",
    "Prepare the datasets and save them to the upload database."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fae3d117-c445-428c-bfd4-33ee5bd5b2b1",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Setup config, database, and libraries."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08e3e121-3691-425e-a0a9-c40e58da6a38",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a727e9a6-e2fe-429a-8ea1-a6625a8b827d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:30:06.745721Z",
     "iopub.status.busy": "2023-06-13T23:30:06.745373Z",
     "iopub.status.idle": "2023-06-13T23:30:07.284294Z",
     "shell.execute_reply": "2023-06-13T23:30:07.283870Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import yaml\n",
    "\n",
    "from datetime import datetime\n",
    "from edotenv import load_edotenv\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine, text, inspect\n",
    "from textwrap import dedent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f518961-e832-4741-8d3e-c601ef72b12d",
   "metadata": {},
   "source": [
    "## Config\n",
    "\n",
    "Load settings from the `config.yml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eca537a3-aba8-4138-81c5-0eef20859f53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:30:07.286647Z",
     "iopub.status.busy": "2023-06-13T23:30:07.286472Z",
     "iopub.status.idle": "2023-06-13T23:30:07.305862Z",
     "shell.execute_reply": "2023-06-13T23:30:07.305414Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('config.yml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    \n",
    "ver = config['Version']\n",
    "abbrv = config['Abbreviation']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5611ce2c-8db9-4ccb-b8fc-371e68da9493",
   "metadata": {},
   "source": [
    "## Database Connection\n",
    "\n",
    "To connect to the database, you need to ensure that you have saved your login with successfully with `bin/login.bat` or `bin/login.sh`:\n",
    "\n",
    "In Windows, run:\n",
    "\n",
    "```\n",
    "bin\\login\n",
    "```\n",
    "\n",
    "In Linux/Mac OS, run:\n",
    "\n",
    "```\n",
    "source bin/login.sh\n",
    "```\n",
    "\n",
    "If these commands run successfully, a `.env` file will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ac3f324-b682-474e-a248-1b98484ad495",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:30:07.308545Z",
     "iopub.status.busy": "2023-06-13T23:30:07.308351Z",
     "iopub.status.idle": "2023-06-13T23:30:07.346279Z",
     "shell.execute_reply": "2023-06-13T23:30:07.345873Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_edotenv('../.env')\n",
    "uengine = create_engine(os.environ['UPLOAD_DB_URL'])\n",
    "is_om = os.environ['UPLOAD_DB_IS_OM'] == 'True'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7baad4d6-d43f-444b-9ccf-cfa45e3c7d46",
   "metadata": {},
   "source": [
    "**Note**: If this fails, try `bin/login.bat` or `bin/login.sh` again."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ba02d65-8f18-4044-b297-6725f3ae3bd8",
   "metadata": {},
   "source": [
    "## Initialize Data Descriptions\n",
    "\n",
    "Create initial data descriptions from the `src/config.yml` file using the `Description` keys under the `Data` list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c264c0d-f17e-4b4a-9d24-7775985f14ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:30:07.348742Z",
     "iopub.status.busy": "2023-06-13T23:30:07.348571Z",
     "iopub.status.idle": "2023-06-13T23:30:07.353464Z",
     "shell.execute_reply": "2023-06-13T23:30:07.352988Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the data descriptions from config.yml\n",
    "ddescribe = []\n",
    "for data in config['Data']:\n",
    "    ddescribe.append({\n",
    "        'dataset': data['Name'],\n",
    "        'description': data['Description']\n",
    "    })\n",
    "ddescribe = pd.DataFrame(ddescribe)\n",
    "\n",
    "# Sort by dataset name\n",
    "ddescribe = ddescribe.sort_values(by=['dataset'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26ba38ce-90a9-49e1-8051-bf4a6995d9cf",
   "metadata": {},
   "source": [
    "Preview data descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bd1898f-9b02-484a-9721-7bd664d222e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:30:07.355606Z",
     "iopub.status.busy": "2023-06-13T23:30:07.355455Z",
     "iopub.status.idle": "2023-06-13T23:30:07.363230Z",
     "shell.execute_reply": "2023-06-13T23:30:07.362837Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cghr10</td>\n",
       "      <td>Centre for Global Health Research for ICD-10 (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cmea10</td>\n",
       "      <td>Central Medical Evaluation Agreement for ICD-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>icd10</td>\n",
       "      <td>International Classification of Diseases Revis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>icd10_cghr10</td>\n",
       "      <td>Mappings to convert from ICD-10 to CGHR-10.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>icd10_cmea10</td>\n",
       "      <td>Mappings to convert from ICD-10 to CMEA-10.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>icd10_icd11</td>\n",
       "      <td>Mappings to convert from ICD-10 to ICD-11.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>icd10_wbd10</td>\n",
       "      <td>Mappings to convert from ICD-10 to WBD-10.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>icd10_wva2016</td>\n",
       "      <td>Mappings to convert from ICD-10 to WVA-2016.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>icd10_wva2022</td>\n",
       "      <td>Mappings to convert from ICD-10 to WVA-2022.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>icd11</td>\n",
       "      <td>International Classification of Diseases Revis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>icd11_icd10</td>\n",
       "      <td>Mappings to convert from ICD-11 to ICD-10.\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wbd10</td>\n",
       "      <td>Wilson's Burden of Disease for ICD-10 (WBD-10)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wva2016</td>\n",
       "      <td>World Health Organization Verbal Autopsy 2016 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>wva2022</td>\n",
       "      <td>World Health Organization Verbal Autopsy 2022 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset                                        description\n",
       "12         cghr10  Centre for Global Health Research for ICD-10 (...\n",
       "6          cmea10  Central Medical Evaluation Agreement for ICD-1...\n",
       "0           icd10  International Classification of Diseases Revis...\n",
       "13   icd10_cghr10        Mappings to convert from ICD-10 to CGHR-10.\n",
       "7    icd10_cmea10        Mappings to convert from ICD-10 to CMEA-10.\n",
       "2     icd10_icd11         Mappings to convert from ICD-10 to ICD-11.\n",
       "5     icd10_wbd10         Mappings to convert from ICD-10 to WBD-10.\n",
       "9   icd10_wva2016       Mappings to convert from ICD-10 to WVA-2016.\n",
       "11  icd10_wva2022       Mappings to convert from ICD-10 to WVA-2022.\n",
       "1           icd11  International Classification of Diseases Revis...\n",
       "3     icd11_icd10  Mappings to convert from ICD-11 to ICD-10.\\n\\n...\n",
       "4           wbd10  Wilson's Burden of Disease for ICD-10 (WBD-10)...\n",
       "8         wva2016  World Health Organization Verbal Autopsy 2016 ...\n",
       "10        wva2022  World Health Organization Verbal Autopsy 2022 ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddescribe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6c7baa0-e0c1-4be9-a6e8-dcd8d512190f",
   "metadata": {},
   "source": [
    "## Initialize Data Dictionaries\n",
    "\n",
    "Create an initial data dictionary from the `src/config.yml` file using the `Description` keys under the `Columns` sub-list in the `Data` list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f0b4926-a3d0-40ab-b5ea-6603fbffbb02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:30:07.366270Z",
     "iopub.status.busy": "2023-06-13T23:30:07.366078Z",
     "iopub.status.idle": "2023-06-13T23:30:10.729166Z",
     "shell.execute_reply": "2023-06-13T23:30:10.728055Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the data dict from config.yml\n",
    "ddict = []\n",
    "for data in config['Data']:\n",
    "    for col in data['Columns']:\n",
    "        ddict.append({\n",
    "            'dataset': data['Name'],\n",
    "            'column': col.get('Rename', col['Name']),\n",
    "            'type': col['Type'],\n",
    "            'description': col['Description']\n",
    "        })\n",
    "ddict= pd.DataFrame(ddict)\n",
    "\n",
    "# Sort by dataset name\n",
    "ddict = ddict.sort_values(by=['dataset'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d1e155d-3ec6-46d3-bd47-a3e192dcae0c",
   "metadata": {},
   "source": [
    "Preview data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acbbde31-c351-4fe7-96ee-29c3b499ae82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:30:10.737063Z",
     "iopub.status.busy": "2023-06-13T23:30:10.736296Z",
     "iopub.status.idle": "2023-06-13T23:30:10.755973Z",
     "shell.execute_reply": "2023-06-13T23:30:10.754916Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>column</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>cghr10</td>\n",
       "      <td>icd10_range</td>\n",
       "      <td>str</td>\n",
       "      <td>ICD-10 range for the CGHR-10 code.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>cghr10</td>\n",
       "      <td>title</td>\n",
       "      <td>str</td>\n",
       "      <td>CGHR-10 title for the code.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>cghr10</td>\n",
       "      <td>age</td>\n",
       "      <td>str</td>\n",
       "      <td>CGHR-10 code age group. Age groups are divided...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>cmea10</td>\n",
       "      <td>icd10_range_short</td>\n",
       "      <td>str</td>\n",
       "      <td>Range of ICD-10 codes in the CMEA-10 block - s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>cmea10</td>\n",
       "      <td>icd10_range</td>\n",
       "      <td>str</td>\n",
       "      <td>Range of ICD-10 codes in the CMEA-10 block - e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>wva2016</td>\n",
       "      <td>icd10_code</td>\n",
       "      <td>str</td>\n",
       "      <td>ICD-10 codes that the WVA-2016 codes can be co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>wva2016</td>\n",
       "      <td>group</td>\n",
       "      <td>Int64</td>\n",
       "      <td>WVA-2016 group containing a range of codes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>wva2022</td>\n",
       "      <td>icd10_range</td>\n",
       "      <td>str</td>\n",
       "      <td>Range of ICD-10 codes for the WVA-2022 codes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>wva2022</td>\n",
       "      <td>title</td>\n",
       "      <td>str</td>\n",
       "      <td>Title for the WVA-2022 code.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>wva2022</td>\n",
       "      <td>code</td>\n",
       "      <td>str</td>\n",
       "      <td>WVA-2022 code from the 2022 WHO VA instrument.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset             column   type   \n",
       "93   cghr10        icd10_range    str  \\\n",
       "92   cghr10              title    str   \n",
       "91   cghr10                age    str   \n",
       "64   cmea10  icd10_range_short    str   \n",
       "63   cmea10        icd10_range    str   \n",
       "..      ...                ...    ...   \n",
       "77  wva2016         icd10_code    str   \n",
       "70  wva2016              group  Int64   \n",
       "86  wva2022        icd10_range    str   \n",
       "85  wva2022              title    str   \n",
       "84  wva2022               code    str   \n",
       "\n",
       "                                          description  \n",
       "93                 ICD-10 range for the CGHR-10 code.  \n",
       "92                        CGHR-10 title for the code.  \n",
       "91  CGHR-10 code age group. Age groups are divided...  \n",
       "64  Range of ICD-10 codes in the CMEA-10 block - s...  \n",
       "63  Range of ICD-10 codes in the CMEA-10 block - e...  \n",
       "..                                                ...  \n",
       "77  ICD-10 codes that the WVA-2016 codes can be co...  \n",
       "70        WVA-2016 group containing a range of codes.  \n",
       "86      Range of ICD-10 codes for the WVA-2022 codes.  \n",
       "85                       Title for the WVA-2022 code.  \n",
       "84     WVA-2022 code from the 2022 WHO VA instrument.  \n",
       "\n",
       "[98 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e20ec2b-9278-4e31-998d-b9aa2083a4e5",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Preprocess datasets, data dictionaries, and data descriptions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d529d2fe-40ce-49a5-8d5e-9c73c594382a",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "Preprocess datasets from the database by:\n",
    "\n",
    "1. Reading raw datasets from files\n",
    "2. Removing rows with all empty values\n",
    "3. Removing and renaming columns, while converting column data types\n",
    "4. Converting whole numbers to integers\n",
    "5. Updating data description and dictionary statistics\n",
    "6. Saving the data description and dictionary with updated statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6823fa2-42ea-44e8-9d50-68ddd233b39e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:30:10.760756Z",
     "iopub.status.busy": "2023-06-13T23:30:10.760345Z",
     "iopub.status.idle": "2023-06-13T23:35:59.046427Z",
     "shell.execute_reply": "2023-06-13T23:35:59.045951Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Store processed data and stats for ddict\n",
    "processed = {}\n",
    "dstats = []\n",
    "\n",
    "# Initialize row and col count\n",
    "ddescribe.insert(1, 'rows', pd.Series(dtype='int'))\n",
    "ddescribe.insert(1, 'columns', pd.Series(dtype='int'))\n",
    "\n",
    "# Download each dataset\n",
    "for data in config['Data']:\n",
    "    \n",
    "     # Get data info\n",
    "    dataset = data['Name']\n",
    "    file = Path(data['File'])\n",
    "    print(f'Processing {dataset}...')\n",
    "    \n",
    "    # 1. Read raw data\n",
    "    ext = file.suffix.lower()\n",
    "    if ext in ['.xls', '.xlsx']:\n",
    "        df = pd.read_excel(file)\n",
    "    elif ext == '.csv':\n",
    "        df = pd.read_csv(file)\n",
    "    else:\n",
    "        raise ValueError(f'Extension {ext} not supported.')\n",
    "        \n",
    "    # 2. Remove rows with all empty values\n",
    "    print('Removing na rows...')\n",
    "    df = df.dropna(axis=0, how='all')\n",
    "    \n",
    "    # 3. Remove/rename cols and convert data type\n",
    "    if 'Columns' in data:\n",
    "        \n",
    "        # 3a. Keep cols\n",
    "        print(f'Extracting columns {dataset}...')\n",
    "        keep_cols = [c['Name'] for c in data['Columns']]\n",
    "        df = df[keep_cols]\n",
    "        \n",
    "        # 3b. Rename cols\n",
    "        print(f'Renaming columns {dataset}...')\n",
    "        rename_cols = {c['Name']: c.get('Rename', c['Name']) for c in data['Columns']}\n",
    "        df = df.rename(columns=rename_cols)\n",
    "        \n",
    "        # 3c. Preprocess cols\n",
    "        for c in data['Columns']:\n",
    "            cname = c.get('Rename', c['Name'])\n",
    "            \n",
    "            # 3c1. Remove leading dashes\n",
    "            if c.get('Remove Leading Dashes', False):\n",
    "                print(f'Removing leading dashes ({cname})...')\n",
    "                df[cname] = df[cname].str.lstrip(' -')\n",
    "                    \n",
    "            # 3c2. Convert data type\n",
    "            if 'Type' in c:\n",
    "                print(f'Converting data type ({cname})...')\n",
    "                df[cname] = df[cname].astype(c['Type'])\n",
    "            \n",
    "    # 4. Convert to whole numbers\n",
    "    for c in df.columns:\n",
    "        if is_numeric_dtype(df[c]):\n",
    "            print(f'Converting whole numbers ({c})...')\n",
    "            is_null = df[c].isnull()\n",
    "            is_int = df[c].apply(lambda x: float.is_integer(x) if isinstance(x, float) else False)\n",
    "            if all(is_null | is_int):\n",
    "                df[c] = df[c].astype('Int64').round(0)\n",
    "            \n",
    "    # 5a. Update data description stats\n",
    "    print('Updating statistics...')\n",
    "    ddescribe.loc[ddescribe['dataset'] == dataset, ['rows', 'columns']] = df.shape\n",
    "    \n",
    "    # 5b. Add ddict stats\n",
    "    stats = df.describe(include='all').transpose()\n",
    "    stats = stats.reset_index()\n",
    "    stats = stats.rename(columns={'index': 'column'})\n",
    "    stats.insert(0, 'dataset', dataset)\n",
    "    dstats.append(stats)\n",
    "    \n",
    "    # Add to processed datasets\n",
    "    processed[dataset] = df\n",
    "    \n",
    "# 7a. Organize data descriptions\n",
    "ddescribe[['rows', 'columns']] = ddescribe[['rows', 'columns']].astype(int)\n",
    "ddescribe = ddescribe.sort_values(by=['dataset'])\n",
    "\n",
    "# 7b1. Prepare stats for ddict to be merged\n",
    "dstats = pd.concat(dstats).reset_index(drop=True) # combine to df per round\n",
    "to_drop = [c for c in dstats.columns if c not in ['dataset', 'column']] # get prev stats cols to drop if exists\n",
    "ddict = ddict.drop(to_drop, axis=1, errors='ignore') # drop prev stats cols if exists\n",
    "\n",
    "# 7b2. Merge stats to ddict\n",
    "ddict = pd.merge(ddict, dstats, on=['dataset', 'column'], how='left') # join stats to unique dataset + col names\n",
    "ddict['count'] = ddict['count'].astype(int)\n",
    "ddict = ddict.reset_index(drop=True).sort_values(by=['dataset'])\n",
    "print('Complete!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7c116b7-5709-418f-8072-bbffec2bdb3e",
   "metadata": {},
   "source": [
    "## Save Data Descriptions\n",
    "\n",
    "Save the data descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746be803-92d4-4fd1-b9b1-fde24111e0b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:35:59.049561Z",
     "iopub.status.busy": "2023-06-13T23:35:59.049163Z",
     "iopub.status.idle": "2023-06-13T23:35:59.054704Z",
     "shell.execute_reply": "2023-06-13T23:35:59.054248Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create folder to store ddict\n",
    "Path('data').mkdir(exist_ok=True)\n",
    "\n",
    "# Save ddescribe as csv\n",
    "ddescribe.to_csv(f'data/{abbrv}_data.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b276ce00-f163-43fc-a23a-5974729f7013",
   "metadata": {},
   "source": [
    "Preview data descriptions with updated statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f45e1cb-c876-44b9-923f-8da37b00b820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:35:59.057050Z",
     "iopub.status.busy": "2023-06-13T23:35:59.056871Z",
     "iopub.status.idle": "2023-06-13T23:35:59.062775Z",
     "shell.execute_reply": "2023-06-13T23:35:59.062411Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ddescribe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77c2aff4-af4c-4c71-a649-8bb59b10430a",
   "metadata": {},
   "source": [
    "## Save Data Dictionary\n",
    "\n",
    "Save the the data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61146cde-1d16-4859-b205-fb376558a65e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:35:59.064804Z",
     "iopub.status.busy": "2023-06-13T23:35:59.064649Z",
     "iopub.status.idle": "2023-06-13T23:35:59.074712Z",
     "shell.execute_reply": "2023-06-13T23:35:59.074360Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create folder to store ddict\n",
    "Path('data').mkdir(exist_ok=True)\n",
    "\n",
    "# Save ddict as csv\n",
    "ddict.to_csv(f'data/{abbrv}_ddict.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49cc27b9-457c-496d-ad2c-8b5fcbeeb632",
   "metadata": {},
   "source": [
    "Preview data dictionary with updated statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f82f56-5cad-4cf9-82b5-a5724d4beb62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:35:59.076977Z",
     "iopub.status.busy": "2023-06-13T23:35:59.076828Z",
     "iopub.status.idle": "2023-06-13T23:35:59.085705Z",
     "shell.execute_reply": "2023-06-13T23:35:59.085372Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ddict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b1e4b15-360e-4d00-9aed-dc28fe0918b7",
   "metadata": {},
   "source": [
    "# Database Upload\n",
    "\n",
    "Upload data and comments to database, while creating views of the most recent data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c3c5964-09b7-47d2-ab71-ef32d4aca18f",
   "metadata": {},
   "source": [
    "## Upload Datasets\n",
    "\n",
    "Upload datasets to created tables in the PostgreSQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2285db-56ab-431f-9a5b-a40a141f20ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:35:59.087785Z",
     "iopub.status.busy": "2023-06-13T23:35:59.087630Z",
     "iopub.status.idle": "2023-06-13T23:46:26.250401Z",
     "shell.execute_reply": "2023-06-13T23:46:26.247721Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for data in config['Data']:\n",
    "\n",
    "    # Get info from config for dataset\n",
    "    version = data.get('Version', ver)\n",
    "    dataset = data['Name']\n",
    "    table = f'{dataset}_v{version}'\n",
    "    schema = data['Upload Schema'] if 'Upload Schema' in data else None\n",
    "\n",
    "    # Upload to db\n",
    "    print(f'Uploading {table}...')\n",
    "    if not inspect(uengine).has_table(table):\n",
    "\n",
    "        # Upload to db depending on whether it has geodata\n",
    "        df = processed[dataset]\n",
    "        if 'Geometry Column' in data:\n",
    "            df.to_postgis(table, uengine, schema=schema, index=False)\n",
    "        else:\n",
    "            df.to_sql(table, uengine, schema=schema, index=False)\n",
    "        print(f'Uploaded {table}!')\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Skip upload if table exists\n",
    "        print(f'Table {table} exists - skipping!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ce311fe-4722-4a91-aaf8-c34e9e6c41bd",
   "metadata": {},
   "source": [
    "## Upload Comments\n",
    "\n",
    "Add table and column comments to uploaded dataset tables by:\n",
    "\n",
    "1. Generating SQL for dataset table comment\n",
    "2. Generating SQL for dataset column comments\n",
    "3. Executing generated SQL statements above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a466bf-cdea-4a5a-881d-9c9b5548753e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:46:26.260410Z",
     "iopub.status.busy": "2023-06-13T23:46:26.259883Z",
     "iopub.status.idle": "2023-06-13T23:46:26.632710Z",
     "shell.execute_reply": "2023-06-13T23:46:26.632144Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql = {}\n",
    "for data in config['Data']:\n",
    "\n",
    "    # Get info from config for dataset\n",
    "    version = data.get('Version', ver)\n",
    "    dataset = data['Name']\n",
    "    table = f'{dataset}_v{version}'\n",
    "\n",
    "    # Add schema if avail\n",
    "    if 'Upload Schema' in data:\n",
    "        schema = data['Upload Schema']\n",
    "        table = f'{schema}.{table}'\n",
    "\n",
    "    # Get ddict for dataset\n",
    "    dd = ddict[ddict['dataset'] == dataset]\n",
    "\n",
    "    # 1. Create sql for table comment\n",
    "    squote = \"'\"\n",
    "    dbquotes = \"''\"\n",
    "    description = ddescribe[ddescribe['dataset'] == dataset]['description']\n",
    "    description = description.tolist()[0].replace(squote, dbquotes)\n",
    "    comment_query = f\"COMMENT ON TABLE {table} IS '{description}';\"\n",
    "\n",
    "    # 2. Create sql for column comments\n",
    "    ncols = dd.shape[0]\n",
    "    col_query = [f\"COMMENT ON COLUMN {table}.{r['column']} IS '{str(r['description']).replace(squote, dbquotes)}';\" for i, r in dd.iterrows()]\n",
    "    col_query = '\\n'.join(col_query)\n",
    "\n",
    "    # 3a. Add table and col comment statements\n",
    "    query = f'--- {table} table comment\\n' + comment_query \\\n",
    "        + f'\\n\\n--- {table} column comments (n={ncols})\\n' + col_query\n",
    "    sql[dataset] = query\n",
    "\n",
    "# 3b. Combine and execute comment statements\n",
    "comment_sql = '\\n\\n'.join(q for dataset, q in sql.items())\n",
    "with uengine.connect() as connection:\n",
    "    connection.execute(text(comment_sql))\n",
    "    connection.execute(text('COMMIT;'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02d68304-7885-4a56-b65e-2ec44e85168a",
   "metadata": {},
   "source": [
    "## Upload Views\n",
    "\n",
    "Create views for the uploaded tables with accompanying view/column comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415d7684-9186-4f3f-9620-14f754d2a1a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:46:26.635690Z",
     "iopub.status.busy": "2023-06-13T23:46:26.635493Z",
     "iopub.status.idle": "2023-06-13T23:46:27.006673Z",
     "shell.execute_reply": "2023-06-13T23:46:27.006311Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql = {}\n",
    "for data in config['Data']:\n",
    "\n",
    "    # Get info from config for dataset\n",
    "    version = data.get('Version', ver)\n",
    "    dataset = data['Name']\n",
    "    table = f'{dataset}_v{version}'\n",
    "\n",
    "    # Add schema if avail\n",
    "    if 'Upload Schema' in data:\n",
    "        schema = data['Upload Schema']\n",
    "        table = f'{schema}.{table}'\n",
    "\n",
    "    # Get ddict for dataset\n",
    "    dd = ddict[ddict['dataset'] == dataset]\n",
    "\n",
    "    # 1. Create view query\n",
    "    view_query = f'DROP VIEW IF EXISTS {dataset}; CREATE OR REPLACE VIEW {dataset} AS (SELECT * FROM {table});'\n",
    "\n",
    "    # 2. Create sql for view comment\n",
    "    squote = \"'\"\n",
    "    dbquotes = \"''\"\n",
    "    description = ddescribe[ddescribe['dataset'] == dataset]['description']\n",
    "    description = description.tolist()[0].replace(squote, dbquotes)\n",
    "    comment_query = f\"COMMENT ON VIEW {dataset} IS '{description}';\"\n",
    "\n",
    "    # 3. Create sql for column comments\n",
    "    ncols = dd.shape[0]\n",
    "    col_query = [f\"COMMENT ON COLUMN {dataset}.{r['column']} IS '{str(r['description']).replace(squote, dbquotes)}';\" for i, r in dd.iterrows()]\n",
    "    col_query = '\\n'.join(col_query)\n",
    "\n",
    "    # 3a. Add view, comment, and column statements\n",
    "    sql[dataset] = f'--- {dataset} view\\n\\n' + view_query \\\n",
    "        + f'\\n\\n--- {dataset} view comment\\n\\n' \\\n",
    "        + comment_query \\\n",
    "        + f'\\n\\n--- {dataset} view column comments (n={ncols})\\n\\n' \\\n",
    "        + col_query\n",
    "\n",
    "# 3b. Combine and execute comment statements\n",
    "view_sql = '\\n\\n'.join([q for dataset, q in sql.items()])\n",
    "with uengine.connect() as connection:\n",
    "    connection.execute(text(view_sql))\n",
    "    connection.execute(text('COMMIT;'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "284c1702-8966-4d7b-9890-ca2cd1473d7d",
   "metadata": {},
   "source": [
    "## Save Comments SQL\n",
    "\n",
    "Save comments sql to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bd54ae-c3b9-415f-98a2-9879e0f10419",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:46:27.009268Z",
     "iopub.status.busy": "2023-06-13T23:46:27.009087Z",
     "iopub.status.idle": "2023-06-13T23:46:27.012834Z",
     "shell.execute_reply": "2023-06-13T23:46:27.012485Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create folder to store database outputs\n",
    "Path('database').mkdir(exist_ok=True)\n",
    "\n",
    "# Save comments sql for tables\n",
    "with open(f'database/{abbrv}_comments_v{ver}.sql', 'w') as file:\n",
    "    file.write(comment_sql)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e60774e-eca7-4edf-aba8-0be8f9f65385",
   "metadata": {},
   "source": [
    "## Save Views SQL\n",
    "\n",
    "Save views sql to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ce391-8d14-4c98-ab32-c85bb662f3c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:46:27.014721Z",
     "iopub.status.busy": "2023-06-13T23:46:27.014604Z",
     "iopub.status.idle": "2023-06-13T23:46:27.017288Z",
     "shell.execute_reply": "2023-06-13T23:46:27.016909Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f'database/{abbrv}_views_v{ver}.sql', 'w') as file:\n",
    "    file.write(view_sql)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22fc550d-8175-4d2a-aea6-6b2410f6df00",
   "metadata": {},
   "source": [
    "# Open Mortality Upload\n",
    "\n",
    "Upload dataset and data records for https://openmortality.org"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90b0c2c1-7dd8-465a-b171-d37485aeef9b",
   "metadata": {},
   "source": [
    "## Add Data Records\n",
    "\n",
    "Query for the current data table or create one if it does not exist.\n",
    "\n",
    "Then add a record for all the data in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb321e4-39c0-4f9f-9cdb-c4a417fd72be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:46:27.019337Z",
     "iopub.status.busy": "2023-06-13T23:46:27.019178Z",
     "iopub.status.idle": "2023-06-13T23:46:27.235955Z",
     "shell.execute_reply": "2023-06-13T23:46:27.235590Z"
    }
   },
   "outputs": [],
   "source": [
    "om_dtable = config['Data Table']\n",
    "om_dschema = config.get('Data Schema', 'public')\n",
    "\n",
    "with uengine.connect() as connection:\n",
    "    \n",
    "    # Create dataset table if not exists\n",
    "    dcreate = text(dedent(\n",
    "        f\"\"\"\n",
    "        --- Data records table\n",
    "        CREATE TABLE IF NOT EXISTS {om_dschema}.{om_dtable} (\n",
    "            data_id SERIAL PRIMARY KEY,\n",
    "            data_name VARCHAR UNIQUE,\n",
    "            format VARCHAR,\n",
    "            is_spatial BOOLEAN,\n",
    "            permission VARCHAR,\n",
    "            publish_date TIMESTAMP WITH TIME ZONE,\n",
    "            status VARCHAR,\n",
    "            tag VARCHAR,\n",
    "            data_desc VARCHAR,\n",
    "            last_update_date VARCHAR,\n",
    "            contact VARCHAR,\n",
    "            category VARCHAR\n",
    "        );\n",
    "        \"\"\"\n",
    "    ))\n",
    "    connection.execute(dcreate)\n",
    "    connection.execute(text('COMMIT;'))\n",
    "    \n",
    "    # Add record for each datum in dataset\n",
    "    dinsert = []\n",
    "    for data in config['Data']:\n",
    "        \n",
    "        # Get metadata\n",
    "        dschema = data.get('Upload Schema', 'public')\n",
    "        dname = data['Name'] + f'_v{ver}'\n",
    "        dformat = 'csv' if 'Geometry Column' not in data else 'geojson'\n",
    "        dspatial = 'Geometry Column' in data\n",
    "        dpermission = data.get('Permission', 'user')\n",
    "        dpublish = str(datetime.now().astimezone())\n",
    "        dtag = data.get('Tag', '')\n",
    "        ddesc = data.get('Description', '').replace(\"'\", \"''\")\n",
    "        dcat = data.get('Category', '')\n",
    "        dcontact = config.get('Contact', 'support@openmortality.org')\n",
    "\n",
    "        # Add data record insert sql\n",
    "        dinsert.append(dedent(\n",
    "            f\"\"\"\n",
    "            --- {dname} data record\n",
    "            INSERT INTO {om_dschema}.{om_dtable} (data_name, \\\"format\\\", is_spatial, \\\"permission\\\", publish_date, status, tag, data_desc, category, contact)\n",
    "            SELECT '{dname}', '{dformat}', '{dspatial}', '{dpermission}', '{dpublish}', 'published', '{dtag}', '{ddesc}', '{dcat}', '{dcontact}'\n",
    "            WHERE NOT EXISTS (SELECT 1 FROM {om_dschema}.{om_dtable} WHERE data_name = '{dname}');\n",
    "            \"\"\"\n",
    "        ))\n",
    "        \n",
    "    # Add data record\n",
    "    dinsert = ''.join(dinsert)\n",
    "    connection.execute(text(dinsert))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5cb5b42-6e1b-4450-bf58-31693a3664ab",
   "metadata": {},
   "source": [
    "## Add Dataset Record\n",
    "\n",
    "Query for the current dataset table or create one if it does not exist.\n",
    "\n",
    "Then add a record for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7f7bd9-b5f7-4837-adb4-05f4de66406c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:46:27.238287Z",
     "iopub.status.busy": "2023-06-13T23:46:27.238157Z",
     "iopub.status.idle": "2023-06-13T23:46:27.727945Z",
     "shell.execute_reply": "2023-06-13T23:46:27.727584Z"
    }
   },
   "outputs": [],
   "source": [
    "om_dstable = config['Dataset Table']\n",
    "om_dsschema = config.get('Dataset Schema', 'public')\n",
    "\n",
    "with uengine.connect() as connection:\n",
    "    \n",
    "    # Create dataset table if not exists\n",
    "    dscreate = text(dedent(\n",
    "        f\"\"\"\n",
    "        --- Dataset records table\n",
    "        CREATE TABLE IF NOT EXISTS {om_dsschema}.{om_dstable} (\n",
    "            dataset_id SERIAL PRIMARY KEY,\n",
    "            title VARCHAR UNIQUE,\n",
    "            title_abbr VARCHAR UNIQUE,\n",
    "            status VARCHAR,\n",
    "            data_id VARCHAR,\n",
    "            publish_date TIMESTAMP WITH TIME ZONE,\n",
    "            tag VARCHAR,\n",
    "            dataset_desc VARCHAR,\n",
    "            contact VARCHAR,\n",
    "            last_update_date TIMESTAMP WITH TIME ZONE,\n",
    "            permission VARCHAR\n",
    "        );\n",
    "        \"\"\"\n",
    "    ))\n",
    "    connection.execute(dscreate)\n",
    "    connection.execute(text('COMMIT;'))\n",
    "    \n",
    "    # Get data ids\n",
    "    dquery = text(\n",
    "        f\"\"\"\n",
    "        SELECT data_id, data_name FROM {om_dschema}.{om_dtable} WHERE data_name = ANY(:names);\n",
    "        \"\"\"\n",
    "    )\n",
    "    dids = pd.read_sql(dquery, uengine, params={\n",
    "        'names': [d['Name'] + f'_v{ver}' for d in config['Data']]\n",
    "    })\n",
    "    dids = ','.join(dids['data_id'].astype(str).tolist())\n",
    "    \n",
    "    # Get markdown description\n",
    "    with open(f'../README.md', 'r') as file:\n",
    "        md = file.read()\n",
    "    ddesc = re.split(r'(\\n#)', md) # split by sections\n",
    "    ddesc = [ddesc[i-1].strip() + d if i > 0 and '\\n#' == ddesc[i -1] else d for i, d in enumerate(ddesc)] # join back hashtags\n",
    "    ddesc = [d for d in ddesc if '## About' in d or '## Citation' in d] # filter for certain sections\n",
    "    ddesc = '\\n\\n'.join(ddesc)\n",
    "    ddesc = ddesc.replace('## About\\n\\n', '') # Remove about section title\n",
    "    ddesc = ddesc.replace(\"'\", \"''\") # replace single quotes with double for pg\n",
    "    \n",
    "    # Set metadata\n",
    "    dstitle = config['Title']\n",
    "    dstitle_abbr_default = ''.join(filter(str.isupper, dstitle.title())).lower()\n",
    "    dstitle_abbr = config.get('Abbreviation', dstitle_abbr_default)\n",
    "    dscontact = config.get('Contact', 'support@openmortality.org')\n",
    "    dspublish = str(datetime.now().astimezone())\n",
    "    dstag = config.get('Tag', '')\n",
    "    dspermission = config.get('Permission', 'user')\n",
    "    \n",
    "    # Add dataset record\n",
    "    dsinsert = text(dedent(\n",
    "        f\"\"\"\n",
    "        --- {dstitle_abbr} dataset record\n",
    "        INSERT INTO {om_dsschema}.{om_dstable} (title, title_abbr, status, data_id, contact, publish_date, tag, dataset_desc, \\\"permission\\\")\n",
    "        SELECT '{dstitle}', '{dstitle_abbr}', 'published', '{dids}', '{dscontact}', '{dspublish}', '{dstag}', '{ddesc}', '{dspermission}'\n",
    "        WHERE NOT EXISTS (SELECT 1 FROM {om_dsschema}.{om_dstable} WHERE title = '{dstitle}');\n",
    "        \"\"\"\n",
    "    ))\n",
    "    connection.execute(dsinsert)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10c86675-bba3-4de3-8ecc-6eab13f2dfe3",
   "metadata": {},
   "source": [
    "## Grant Access to User\n",
    "\n",
    "Grant access to OM user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab2dc98-b1fb-4d10-a794-006a4859243f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:46:27.730179Z",
     "iopub.status.busy": "2023-06-13T23:46:27.730012Z",
     "iopub.status.idle": "2023-06-13T23:46:27.732973Z",
     "shell.execute_reply": "2023-06-13T23:46:27.732663Z"
    }
   },
   "outputs": [],
   "source": [
    "if is_om:\n",
    "    omuser = config['Database User']\n",
    "    with uengine.connect() as connection:\n",
    "        \n",
    "        # Create grant sql\n",
    "        grantsql = ['--- Grant select on data for OM user']\n",
    "        for data in config['Data']:\n",
    "            dtable = data['Name'] + f'_v{ver}'\n",
    "            dschema = data.get('Upload Schema', 'public')\n",
    "            grantsql.append(f'GRANT SELECT ON TABLE {dschema}.{dtable} TO {omuser};')\n",
    "        grantsql = text('\\n'.join(grantsql))\n",
    "        \n",
    "        # Grant access to user for added tables\n",
    "        connection.execute(grantsql)\n",
    "        connection.execute(text('COMMIT;'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41ff54d7-4e04-4ae8-94a8-1b851eebc3d5",
   "metadata": {},
   "source": [
    "## Refresh Dataset Records View\n",
    "\n",
    "Refresh materialized view for dataset records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d61a0bd-dbb7-4cd5-8954-bba4d57c9cb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:46:27.735064Z",
     "iopub.status.busy": "2023-06-13T23:46:27.734889Z",
     "iopub.status.idle": "2023-06-13T23:46:27.737443Z",
     "shell.execute_reply": "2023-06-13T23:46:27.737005Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_om:\n",
    "    matview = config['Dataset Refresh View']\n",
    "    with uengine.connect() as connection:\n",
    "        refreshsql = text(f'--- Refresh dataset records materialized view \\nREFRESH MATERIALIZED VIEW {matview};')\n",
    "        connection.execute(refreshsql)\n",
    "        connection.execute(text('COMMIT;'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b168e22-146f-4909-80a3-f9696f3c0ec2",
   "metadata": {},
   "source": [
    "## Save Data Records SQL\n",
    "\n",
    "Save data records sql to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d47cf7-8a22-4d3a-92f7-0196ae722c6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:46:27.739404Z",
     "iopub.status.busy": "2023-06-13T23:46:27.739271Z",
     "iopub.status.idle": "2023-06-13T23:46:27.742112Z",
     "shell.execute_reply": "2023-06-13T23:46:27.741792Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f'database/{abbrv}_data_v{ver}.sql', 'w') as file:\n",
    "    if is_om:\n",
    "        file.write(str(dcreate) + str(dinsert) + '\\n' + str(grantsql))\n",
    "    else:\n",
    "        file.write(str(dcreate) + str(dinsert))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "468703aa-9257-4297-8189-3f016e25b574",
   "metadata": {},
   "source": [
    "## Save Dataset Records SQL\n",
    "\n",
    "Save dataset records sql to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f86bed4-1d66-463b-b9bf-cdf2b4f2485c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:46:27.743926Z",
     "iopub.status.busy": "2023-06-13T23:46:27.743793Z",
     "iopub.status.idle": "2023-06-13T23:46:27.746512Z",
     "shell.execute_reply": "2023-06-13T23:46:27.746164Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f'database/{abbrv}_dataset_v{ver}.sql', 'w') as file:\n",
    "    if is_om:\n",
    "        file.write(str(dscreate) + str(dsinsert) + '\\n' + str(refreshsql))\n",
    "    else:\n",
    "        file.write(str(dscreate) + str(dsinsert) + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eafd26f9-1d38-4654-adf1-7b988c06f543",
   "metadata": {},
   "source": [
    "# Close Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60bf6a8-f2c7-4df6-a55e-2809950122c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:46:27.748469Z",
     "iopub.status.busy": "2023-06-13T23:46:27.748221Z",
     "iopub.status.idle": "2023-06-13T23:46:27.750683Z",
     "shell.execute_reply": "2023-06-13T23:46:27.750301Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "engine.dispose()\n",
    "uengine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
