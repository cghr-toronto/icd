{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c8cd207-b284-49ec-8ae1-08504d76b8a7",
   "metadata": {},
   "source": [
    "# Update\n",
    "\n",
    "Update the table and column comments on the database."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fae3d117-c445-428c-bfd4-33ee5bd5b2b1",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Setup config, database, and libraries."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08e3e121-3691-425e-a0a9-c40e58da6a38",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a727e9a6-e2fe-429a-8ea1-a6625a8b827d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:30:06.745721Z",
     "iopub.status.busy": "2023-06-13T23:30:06.745373Z",
     "iopub.status.idle": "2023-06-13T23:30:07.284294Z",
     "shell.execute_reply": "2023-06-13T23:30:07.283870Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import yaml\n",
    "\n",
    "from datetime import datetime\n",
    "from edotenv import load_edotenv\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine, text, inspect\n",
    "from textwrap import dedent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f518961-e832-4741-8d3e-c601ef72b12d",
   "metadata": {},
   "source": [
    "## Config\n",
    "\n",
    "Load settings from the `config.yml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "eca537a3-aba8-4138-81c5-0eef20859f53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:30:07.286647Z",
     "iopub.status.busy": "2023-06-13T23:30:07.286472Z",
     "iopub.status.idle": "2023-06-13T23:30:07.305862Z",
     "shell.execute_reply": "2023-06-13T23:30:07.305414Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('config.yml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    \n",
    "ver = config['Version']\n",
    "abbrv = config['Abbreviation']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5611ce2c-8db9-4ccb-b8fc-371e68da9493",
   "metadata": {},
   "source": [
    "## Database Connection\n",
    "\n",
    "To connect to the database, you need to ensure that you have saved your login with successfully with `bin/login.bat` or `bin/login.sh`:\n",
    "\n",
    "In Windows, run:\n",
    "\n",
    "```\n",
    "bin\\login\n",
    "```\n",
    "\n",
    "In Linux/Mac OS, run:\n",
    "\n",
    "```\n",
    "source bin/login.sh\n",
    "```\n",
    "\n",
    "If these commands run successfully, a `.env` file will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9ac3f324-b682-474e-a248-1b98484ad495",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:30:07.308545Z",
     "iopub.status.busy": "2023-06-13T23:30:07.308351Z",
     "iopub.status.idle": "2023-06-13T23:30:07.346279Z",
     "shell.execute_reply": "2023-06-13T23:30:07.345873Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_edotenv('../.env')\n",
    "engine = create_engine(os.environ['DB_URL'])\n",
    "uengine = create_engine(os.environ['UPLOAD_DB_URL'])\n",
    "is_om = os.environ['UPLOAD_DB_IS_OM'] == 'True'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7baad4d6-d43f-444b-9ccf-cfa45e3c7d46",
   "metadata": {},
   "source": [
    "**Note**: If this fails, try `bin/login.bat` or `bin/login.sh` again."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ba02d65-8f18-4044-b297-6725f3ae3bd8",
   "metadata": {},
   "source": [
    "## Read Data Descriptions\n",
    "\n",
    "Read data descriptions from the `src/config.yml` file using the `Description` keys under the `Data` list.\n",
    "\n",
    "Also add stats to the data descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7c264c0d-f17e-4b4a-9d24-7775985f14ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:30:07.348742Z",
     "iopub.status.busy": "2023-06-13T23:30:07.348571Z",
     "iopub.status.idle": "2023-06-13T23:30:07.353464Z",
     "shell.execute_reply": "2023-06-13T23:30:07.352988Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the data descriptions from config.yml\n",
    "ddescribe_config = []\n",
    "for data in config['Data']:\n",
    "    ddescribe_config.append({\n",
    "        'dataset': data['Name'],\n",
    "        'description': data['Description']\n",
    "    })\n",
    "ddescribe_config = pd.DataFrame(ddescribe_config)\n",
    "\n",
    "# Read the known data descriptions\n",
    "ddescribe = pd.read_csv(f'data/{abbrv}_data.csv')\n",
    "\n",
    "# Update the known data descriptions\n",
    "ddescribe = pd.merge(ddescribe[['dataset', 'columns', 'rows']], ddescribe_config, on = 'dataset', how = 'left')\n",
    "\n",
    "# Sort by dataset name\n",
    "ddescribe = ddescribe.sort_values(by = ['dataset'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26ba38ce-90a9-49e1-8051-bf4a6995d9cf",
   "metadata": {},
   "source": [
    "Preview data descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9bd1898f-9b02-484a-9721-7bd664d222e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:30:07.355606Z",
     "iopub.status.busy": "2023-06-13T23:30:07.355455Z",
     "iopub.status.idle": "2023-06-13T23:30:07.363230Z",
     "shell.execute_reply": "2023-06-13T23:30:07.362837Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>columns</th>\n",
       "      <th>rows</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>healsl_rd1_adult</td>\n",
       "      <td>367</td>\n",
       "      <td>5003</td>\n",
       "      <td>Adult Verbal Autopsy (VA) data for survey roun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>healsl_rd1_adult_age</td>\n",
       "      <td>11</td>\n",
       "      <td>5003</td>\n",
       "      <td>Specific ages for the [Adult VA Data (HEAL-SL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>healsl_rd1_adult_narrative</td>\n",
       "      <td>3</td>\n",
       "      <td>4987</td>\n",
       "      <td>Narratives for the [Adult VA Data (HEAL-SL Rou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>healsl_rd1_child</td>\n",
       "      <td>313</td>\n",
       "      <td>3004</td>\n",
       "      <td>Child Verbal Autopsy (VA) data for survey roun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>healsl_rd1_child_age</td>\n",
       "      <td>9</td>\n",
       "      <td>3004</td>\n",
       "      <td>Specific ages for the [Child VA Data (HEAL-SL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>healsl_rd1_child_narrative</td>\n",
       "      <td>3</td>\n",
       "      <td>2998</td>\n",
       "      <td>Narratives for the [Child VA Data (HEAL-SL Rou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>healsl_rd1_geo</td>\n",
       "      <td>10</td>\n",
       "      <td>38527</td>\n",
       "      <td>Household Global Positioning System (GPS) loca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>healsl_rd1_household</td>\n",
       "      <td>61</td>\n",
       "      <td>344466</td>\n",
       "      <td>Household data for survey round 1 of the Healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>healsl_rd1_household_age</td>\n",
       "      <td>3</td>\n",
       "      <td>343120</td>\n",
       "      <td>Specific household member ages for the [Househ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>healsl_rd1_neo</td>\n",
       "      <td>265</td>\n",
       "      <td>586</td>\n",
       "      <td>Neonate Verbal Autopsy (VA) data for survey ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>healsl_rd1_neo_age</td>\n",
       "      <td>9</td>\n",
       "      <td>586</td>\n",
       "      <td>Specific ages for the [Neonate VA Data (HEAL-S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>healsl_rd1_neo_narrative</td>\n",
       "      <td>3</td>\n",
       "      <td>585</td>\n",
       "      <td>Narratives for the [Neonate VA Data (HEAL-SL R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>healsl_rd2_adult</td>\n",
       "      <td>391</td>\n",
       "      <td>2033</td>\n",
       "      <td>Adult Verbal Autopsy (VA) data for survey roun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>healsl_rd2_adult_age</td>\n",
       "      <td>11</td>\n",
       "      <td>2033</td>\n",
       "      <td>Specific ages for the [Adult VA Data (HEAL-SL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>healsl_rd2_adult_narrative</td>\n",
       "      <td>3</td>\n",
       "      <td>2025</td>\n",
       "      <td>Narratives for the [Adult VA Data (HEAL-SL Rou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>healsl_rd2_child</td>\n",
       "      <td>312</td>\n",
       "      <td>1060</td>\n",
       "      <td>Child Verbal Autopsy (VA) data for survey roun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>healsl_rd2_child_age</td>\n",
       "      <td>9</td>\n",
       "      <td>1060</td>\n",
       "      <td>Specific ages for the [Child VA Data (HEAL-SL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>healsl_rd2_child_narrative</td>\n",
       "      <td>3</td>\n",
       "      <td>1059</td>\n",
       "      <td>Narratives for the [Child VA Data (HEAL-SL Rou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>healsl_rd2_geo</td>\n",
       "      <td>10</td>\n",
       "      <td>39390</td>\n",
       "      <td>Household Global Positioning System (GPS) loca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>healsl_rd2_household</td>\n",
       "      <td>112</td>\n",
       "      <td>415598</td>\n",
       "      <td>Household data for survey round 2 of the Healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>healsl_rd2_household_age</td>\n",
       "      <td>6</td>\n",
       "      <td>412662</td>\n",
       "      <td>Specific household member ages for the [Househ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>healsl_rd2_neo</td>\n",
       "      <td>262</td>\n",
       "      <td>234</td>\n",
       "      <td>Neonate Verbal Autopsy (VA) data for survey ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>healsl_rd2_neo_age</td>\n",
       "      <td>9</td>\n",
       "      <td>234</td>\n",
       "      <td>Specific ages for the [Neonate VA Data (HEAL-S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>healsl_rd2_neo_narrative</td>\n",
       "      <td>3</td>\n",
       "      <td>233</td>\n",
       "      <td>Narratives for the [Neonate VA Data (HEAL-SL R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       dataset  columns    rows   \n",
       "0             healsl_rd1_adult      367    5003  \\\n",
       "1         healsl_rd1_adult_age       11    5003   \n",
       "2   healsl_rd1_adult_narrative        3    4987   \n",
       "3             healsl_rd1_child      313    3004   \n",
       "4         healsl_rd1_child_age        9    3004   \n",
       "5   healsl_rd1_child_narrative        3    2998   \n",
       "6               healsl_rd1_geo       10   38527   \n",
       "7         healsl_rd1_household       61  344466   \n",
       "8     healsl_rd1_household_age        3  343120   \n",
       "9               healsl_rd1_neo      265     586   \n",
       "10          healsl_rd1_neo_age        9     586   \n",
       "11    healsl_rd1_neo_narrative        3     585   \n",
       "12            healsl_rd2_adult      391    2033   \n",
       "13        healsl_rd2_adult_age       11    2033   \n",
       "14  healsl_rd2_adult_narrative        3    2025   \n",
       "15            healsl_rd2_child      312    1060   \n",
       "16        healsl_rd2_child_age        9    1060   \n",
       "17  healsl_rd2_child_narrative        3    1059   \n",
       "18              healsl_rd2_geo       10   39390   \n",
       "19        healsl_rd2_household      112  415598   \n",
       "20    healsl_rd2_household_age        6  412662   \n",
       "21              healsl_rd2_neo      262     234   \n",
       "22          healsl_rd2_neo_age        9     234   \n",
       "23    healsl_rd2_neo_narrative        3     233   \n",
       "\n",
       "                                          description  \n",
       "0   Adult Verbal Autopsy (VA) data for survey roun...  \n",
       "1   Specific ages for the [Adult VA Data (HEAL-SL ...  \n",
       "2   Narratives for the [Adult VA Data (HEAL-SL Rou...  \n",
       "3   Child Verbal Autopsy (VA) data for survey roun...  \n",
       "4   Specific ages for the [Child VA Data (HEAL-SL ...  \n",
       "5   Narratives for the [Child VA Data (HEAL-SL Rou...  \n",
       "6   Household Global Positioning System (GPS) loca...  \n",
       "7   Household data for survey round 1 of the Healt...  \n",
       "8   Specific household member ages for the [Househ...  \n",
       "9   Neonate Verbal Autopsy (VA) data for survey ro...  \n",
       "10  Specific ages for the [Neonate VA Data (HEAL-S...  \n",
       "11  Narratives for the [Neonate VA Data (HEAL-SL R...  \n",
       "12  Adult Verbal Autopsy (VA) data for survey roun...  \n",
       "13  Specific ages for the [Adult VA Data (HEAL-SL ...  \n",
       "14  Narratives for the [Adult VA Data (HEAL-SL Rou...  \n",
       "15  Child Verbal Autopsy (VA) data for survey roun...  \n",
       "16  Specific ages for the [Child VA Data (HEAL-SL ...  \n",
       "17  Narratives for the [Child VA Data (HEAL-SL Rou...  \n",
       "18  Household Global Positioning System (GPS) loca...  \n",
       "19  Household data for survey round 2 of the Healt...  \n",
       "20  Specific household member ages for the [Househ...  \n",
       "21  Neonate Verbal Autopsy (VA) data for survey ro...  \n",
       "22  Specific ages for the [Neonate VA Data (HEAL-S...  \n",
       "23  Narratives for the [Neonate VA Data (HEAL-SL R...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddescribe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6c7baa0-e0c1-4be9-a6e8-dcd8d512190f",
   "metadata": {},
   "source": [
    "## Read Data Dictionaries\n",
    "\n",
    "Read data dictionary by getting the column comments from the database without the private or excluded columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5f0b4926-a3d0-40ab-b5ea-6603fbffbb02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:30:07.366270Z",
     "iopub.status.busy": "2023-06-13T23:30:07.366078Z",
     "iopub.status.idle": "2023-06-13T23:30:10.729166Z",
     "shell.execute_reply": "2023-06-13T23:30:10.728055Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ddict = []\n",
    "for data in config['Data']:\n",
    "    \n",
    "    # Prepare query statement\n",
    "    query = text(\n",
    "        \"\"\"\n",
    "        SELECT\n",
    "            table_name AS dataset,\n",
    "            column_name AS column,\n",
    "            data_type AS type,\n",
    "            col_description((table_schema||'.'||table_name)::regclass::oid, ordinal_position) AS description\n",
    "        FROM\n",
    "            information_schema.columns\n",
    "        WHERE\n",
    "            table_name = :table\n",
    "            AND\n",
    "            table_schema = :schema\n",
    "            AND\n",
    "            NOT column_name = ANY(:cols)\n",
    "        ORDER BY table_name, ordinal_position;\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Get column comments for dataset\n",
    "    comments = pd.read_sql(query, engine, params={\n",
    "        'table': data['Table'],\n",
    "        'schema': data.get('Schema', 'public'),\n",
    "        'cols': config.get('Excluded Columns', [''])\n",
    "    })\n",
    "    \n",
    "    # Modify dataset name\n",
    "    comments['dataset'] = data['Name']\n",
    "    \n",
    "    # Change character to character varying for flexibility\n",
    "    comments.loc[comments['type'] == 'character', ['type']] = 'character varying'\n",
    "    \n",
    "    # Add dataset ddict to appropriate round\n",
    "    ddict.append(comments)\n",
    "\n",
    "# Combine ddict\n",
    "ddict = pd.concat(ddict, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d1e155d-3ec6-46d3-bd47-a3e192dcae0c",
   "metadata": {},
   "source": [
    "Preview data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "acbbde31-c351-4fe7-96ee-29c3b499ae82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:30:10.737063Z",
     "iopub.status.busy": "2023-06-13T23:30:10.736296Z",
     "iopub.status.idle": "2023-06-13T23:30:10.755973Z",
     "shell.execute_reply": "2023-06-13T23:30:10.754916Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>column</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>healsl_rd1_geo</td>\n",
       "      <td>areaid</td>\n",
       "      <td>bigint</td>\n",
       "      <td>Unique enumeration area identifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>healsl_rd1_geo</td>\n",
       "      <td>timelog</td>\n",
       "      <td>timestamp with time zone</td>\n",
       "      <td>Date and time of enumeration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>healsl_rd1_geo</td>\n",
       "      <td>gps_latitude</td>\n",
       "      <td>text</td>\n",
       "      <td>GPS latitude of the house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>healsl_rd1_geo</td>\n",
       "      <td>gps_latitude_alt</td>\n",
       "      <td>double precision</td>\n",
       "      <td>GPS latitude of the house (Data coordinator al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>healsl_rd1_geo</td>\n",
       "      <td>gps_longitude</td>\n",
       "      <td>text</td>\n",
       "      <td>GPS longitude of the house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2183</th>\n",
       "      <td>healsl_rd2_neo_age</td>\n",
       "      <td>age_unit_cod</td>\n",
       "      <td>text</td>\n",
       "      <td>How old was (s)he (the deceased)? (Originated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>healsl_rd2_neo_age</td>\n",
       "      <td>age_value_cod</td>\n",
       "      <td>integer</td>\n",
       "      <td>How old was (s)he (the deceased)? (Originated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>healsl_rd2_neo_narrative</td>\n",
       "      <td>rowid</td>\n",
       "      <td>bigint</td>\n",
       "      <td>Unique row identifier for this dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>healsl_rd2_neo_narrative</td>\n",
       "      <td>timelog</td>\n",
       "      <td>timestamp with time zone</td>\n",
       "      <td>Date and time of enumeration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>healsl_rd2_neo_narrative</td>\n",
       "      <td>summary</td>\n",
       "      <td>text</td>\n",
       "      <td>Positive symptoms in chronological order</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2188 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       dataset            column                      type   \n",
       "0               healsl_rd1_geo            areaid                    bigint  \\\n",
       "1               healsl_rd1_geo           timelog  timestamp with time zone   \n",
       "2               healsl_rd1_geo      gps_latitude                      text   \n",
       "3               healsl_rd1_geo  gps_latitude_alt          double precision   \n",
       "4               healsl_rd1_geo     gps_longitude                      text   \n",
       "...                        ...               ...                       ...   \n",
       "2183        healsl_rd2_neo_age      age_unit_cod                      text   \n",
       "2184        healsl_rd2_neo_age     age_value_cod                   integer   \n",
       "2185  healsl_rd2_neo_narrative             rowid                    bigint   \n",
       "2186  healsl_rd2_neo_narrative           timelog  timestamp with time zone   \n",
       "2187  healsl_rd2_neo_narrative           summary                      text   \n",
       "\n",
       "                                            description  \n",
       "0                    Unique enumeration area identifier  \n",
       "1                          Date and time of enumeration  \n",
       "2                             GPS latitude of the house  \n",
       "3     GPS latitude of the house (Data coordinator al...  \n",
       "4                            GPS longitude of the house  \n",
       "...                                                 ...  \n",
       "2183  How old was (s)he (the deceased)? (Originated ...  \n",
       "2184  How old was (s)he (the deceased)? (Originated ...  \n",
       "2185             Unique row identifier for this dataset  \n",
       "2186                       Date and time of enumeration  \n",
       "2187           Positive symptoms in chronological order  \n",
       "\n",
       "[2188 rows x 4 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b1e4b15-360e-4d00-9aed-dc28fe0918b7",
   "metadata": {},
   "source": [
    "# Database Update\n",
    "\n",
    "Update comments and views in database with data dictionaries and descriptions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ce311fe-4722-4a91-aaf8-c34e9e6c41bd",
   "metadata": {},
   "source": [
    "## Upload Comments\n",
    "\n",
    "Add table and column comments to uploaded dataset tables by:\n",
    "\n",
    "1. Generating SQL for dataset table comment\n",
    "2. Generating SQL for dataset column comments\n",
    "3. Executing generated SQL statements above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "12a466bf-cdea-4a5a-881d-9c9b5548753e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:46:26.260410Z",
     "iopub.status.busy": "2023-06-13T23:46:26.259883Z",
     "iopub.status.idle": "2023-06-13T23:46:26.632710Z",
     "shell.execute_reply": "2023-06-13T23:46:26.632144Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql = {}\n",
    "for data in config['Data']:\n",
    "\n",
    "    # Get info from config for dataset\n",
    "    version = data.get('Version', ver)\n",
    "    dataset = data['Name']\n",
    "    table = f'{dataset}_v{version}'\n",
    "\n",
    "    # Add schema if avail\n",
    "    if 'Upload Schema' in data:\n",
    "        schema = data['Upload Schema']\n",
    "        table = f'{schema}.{table}'\n",
    "\n",
    "    # Get ddict for dataset\n",
    "    dd = ddict[ddict['dataset'] == dataset]\n",
    "\n",
    "    # 1. Create sql for table comment\n",
    "    squote = \"'\"\n",
    "    dbquotes = \"''\"\n",
    "    description = ddescribe[ddescribe['dataset'] == dataset]['description']\n",
    "    description = description.tolist()[0].replace(squote, dbquotes)\n",
    "    comment_query = f\"COMMENT ON TABLE {table} IS '{description}';\"\n",
    "\n",
    "    # 2. Create sql for column comments\n",
    "    ncols = dd.shape[0]\n",
    "    col_query = [f\"COMMENT ON COLUMN {table}.{r['column']} IS '{str(r['description']).replace(squote, dbquotes)}';\" for i, r in dd.iterrows()]\n",
    "    col_query = '\\n'.join(col_query)\n",
    "\n",
    "    # 3a. Add table and col comment statements\n",
    "    query = f'--- {table} table comment\\n' + comment_query \\\n",
    "        + f'\\n\\n--- {table} column comments (n={ncols})\\n' + col_query\n",
    "    sql[dataset] = query\n",
    "\n",
    "# 3b. Combine and execute comment statements\n",
    "comment_sql = '\\n\\n'.join(q for dataset, q in sql.items())\n",
    "with uengine.connect() as connection:\n",
    "    connection.execute(text(comment_sql))\n",
    "    connection.execute(text('COMMIT;'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02d68304-7885-4a56-b65e-2ec44e85168a",
   "metadata": {},
   "source": [
    "## Upload Views\n",
    "\n",
    "Create views for the uploaded tables with accompanying view/column comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "415d7684-9186-4f3f-9620-14f754d2a1a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:46:26.635690Z",
     "iopub.status.busy": "2023-06-13T23:46:26.635493Z",
     "iopub.status.idle": "2023-06-13T23:46:27.006673Z",
     "shell.execute_reply": "2023-06-13T23:46:27.006311Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql = {}\n",
    "for data in config['Data']:\n",
    "\n",
    "    # Get info from config for dataset\n",
    "    version = data.get('Version', ver)\n",
    "    dataset = data['Name']\n",
    "    table = f'{dataset}_v{version}'\n",
    "\n",
    "    # Add schema if avail\n",
    "    if 'Upload Schema' in data:\n",
    "        schema = data['Upload Schema']\n",
    "        table = f'{schema}.{table}'\n",
    "\n",
    "    # Get ddict for dataset\n",
    "    dd = ddict[ddict['dataset'] == dataset]\n",
    "\n",
    "    # 1. Create view query\n",
    "    view_query = f'DROP VIEW IF EXISTS {dataset}; CREATE OR REPLACE VIEW {dataset} AS (SELECT * FROM {table});'\n",
    "\n",
    "    # 2. Create sql for view comment\n",
    "    squote = \"'\"\n",
    "    dbquotes = \"''\"\n",
    "    description = ddescribe[ddescribe['dataset'] == dataset]['description']\n",
    "    description = description.tolist()[0].replace(squote, dbquotes)\n",
    "    cols = ddescribe[ddescribe['dataset'] == data['Name']]['columns'].tolist()[0]\n",
    "    rows = ddescribe[ddescribe['dataset'] == data['Name']]['rows'].tolist()[0]\n",
    "    comment_query = f\"COMMENT ON VIEW {dataset} IS '{description}\\n\\n* **Columns**: {cols}\\n\\n* **Rows**: {rows}';\"\n",
    "\n",
    "    # 3. Create sql for column comments\n",
    "    ncols = dd.shape[0]\n",
    "    col_query = [f\"COMMENT ON COLUMN {dataset}.{r['column']} IS '{str(r['description']).replace(squote, dbquotes)}';\" for i, r in dd.iterrows()]\n",
    "    col_query = '\\n'.join(col_query)\n",
    "\n",
    "    # 3a. Add view, comment, and column statements\n",
    "    sql[dataset] = f'--- {dataset} view\\n\\n' + view_query \\\n",
    "        + f'\\n\\n--- {dataset} view comment\\n\\n' \\\n",
    "        + comment_query \\\n",
    "        + f'\\n\\n--- {dataset} view column comments (n={ncols})\\n\\n' \\\n",
    "        + col_query\n",
    "\n",
    "# 3b. Combine and execute comment statements\n",
    "view_sql = '\\n\\n'.join([q for dataset, q in sql.items()])\n",
    "with uengine.connect() as connection:\n",
    "    connection.execute(text(view_sql))\n",
    "    connection.execute(text('COMMIT;'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "284c1702-8966-4d7b-9890-ca2cd1473d7d",
   "metadata": {},
   "source": [
    "## Save Comments SQL\n",
    "\n",
    "Save comments sql to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d0bd54ae-c3b9-415f-98a2-9879e0f10419",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:46:27.009268Z",
     "iopub.status.busy": "2023-06-13T23:46:27.009087Z",
     "iopub.status.idle": "2023-06-13T23:46:27.012834Z",
     "shell.execute_reply": "2023-06-13T23:46:27.012485Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create folder to store database outputs\n",
    "Path('database').mkdir(exist_ok=True)\n",
    "\n",
    "# Save comments sql for tables\n",
    "with open(f'database/{abbrv}_comments_v{ver}.sql', 'w') as file:\n",
    "    file.write(comment_sql)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e60774e-eca7-4edf-aba8-0be8f9f65385",
   "metadata": {},
   "source": [
    "## Save Views SQL\n",
    "\n",
    "Save views sql to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f00ce391-8d14-4c98-ab32-c85bb662f3c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:46:27.014721Z",
     "iopub.status.busy": "2023-06-13T23:46:27.014604Z",
     "iopub.status.idle": "2023-06-13T23:46:27.017288Z",
     "shell.execute_reply": "2023-06-13T23:46:27.016909Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f'database/{abbrv}_views_v{ver}.sql', 'w') as file:\n",
    "    file.write(view_sql)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22fc550d-8175-4d2a-aea6-6b2410f6df00",
   "metadata": {},
   "source": [
    "# Open Mortality Upload\n",
    "\n",
    "Upload dataset and data records for https://openmortality.org"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90b0c2c1-7dd8-465a-b171-d37485aeef9b",
   "metadata": {},
   "source": [
    "## Add Data Records\n",
    "\n",
    "Query for the current data table or create one if it does not exist.\n",
    "\n",
    "Then add a record for all the data in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dcb321e4-39c0-4f9f-9cdb-c4a417fd72be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:46:27.019337Z",
     "iopub.status.busy": "2023-06-13T23:46:27.019178Z",
     "iopub.status.idle": "2023-06-13T23:46:27.235955Z",
     "shell.execute_reply": "2023-06-13T23:46:27.235590Z"
    }
   },
   "outputs": [],
   "source": [
    "om_dtable = config['Data Table']\n",
    "om_dschema = config.get('Data Schema', 'public')\n",
    "\n",
    "with uengine.connect() as connection:\n",
    "    \n",
    "    # Create dataset table if not exists\n",
    "    dcreate = text(dedent(\n",
    "        f\"\"\"\n",
    "        --- Data records table\n",
    "        CREATE TABLE IF NOT EXISTS {om_dschema}.{om_dtable} (\n",
    "            data_id SERIAL PRIMARY KEY,\n",
    "            title VARCHAR,\n",
    "            data_name VARCHAR UNIQUE,\n",
    "            format VARCHAR,\n",
    "            is_spatial BOOLEAN,\n",
    "            permission VARCHAR,\n",
    "            publish_date TIMESTAMP WITH TIME ZONE,\n",
    "            last_updated_date TIMESTAMP WITH TIME ZONE,\n",
    "            status VARCHAR,\n",
    "            tag VARCHAR,\n",
    "            data_desc VARCHAR,\n",
    "            last_update_date VARCHAR,\n",
    "            contact VARCHAR,\n",
    "            category VARCHAR,\n",
    "            data_columns BIGINT,\n",
    "            data_rows BIGINT\n",
    "        );\n",
    "        \"\"\"\n",
    "    ))\n",
    "    connection.execute(dcreate)\n",
    "    connection.execute(text('COMMIT;'))\n",
    "    \n",
    "    # Add record for each datum in dataset\n",
    "    dinsert = []\n",
    "    dupdate = []\n",
    "    for data in config['Data']:\n",
    "        \n",
    "        # Get metadata\n",
    "        dschema = data.get('Upload Schema', 'public')\n",
    "        dname = data['Name'] + f'_v{ver}'\n",
    "        dtitle = data.get('Title', '')\n",
    "        dformat = 'csv' if 'Geometry Column' not in data else 'geojson'\n",
    "        dspatial = 'Geometry Column' in data\n",
    "        dpermission = data.get('Permission', 'user')\n",
    "        dpublish = str(datetime.now().astimezone())\n",
    "        dtag = data.get('Tag', '')\n",
    "        ddesc = data.get('Description', '').replace(\"'\", \"''\")\n",
    "        dcat = data.get('Category', '')\n",
    "        dcontact = config.get('Contact', 'support@openmortality.org')\n",
    "\n",
    "        # Add metadata to desc\n",
    "        dmeta = data.get('Metadata', None)\n",
    "        if isinstance(dmeta, dict):\n",
    "            dmeta_list = '\\n'.join([f'* **{k}**: {v}' for k, v in dmeta.items()])\n",
    "            ddesc = ddesc + '\\n' + dmeta_list\n",
    "        \n",
    "        # Add file, rows and cols to desc\n",
    "        cols = ddescribe[ddescribe['dataset'] == data['Name']]['columns'].tolist()[0]\n",
    "        rows = ddescribe[ddescribe['dataset'] == data['Name']]['rows'].tolist()[0]\n",
    "        ddesc = ddesc + f'\\n* **File**: {dname}.{dformat}\\n* **Dimensions**: {\"{:,}\".format(cols)} columns / {\"{:,}\".format(rows)} rows'\n",
    "\n",
    "        # Add data record insert sql\n",
    "        dinsert.append(dedent(\n",
    "            f\"\"\"\n",
    "            --- {dname} data record\n",
    "            INSERT INTO {om_dschema}.{om_dtable} (title, data_name, \\\"format\\\", is_spatial, \\\"permission\\\", publish_date, status, tag, data_desc, category, contact, data_columns, data_rows)\n",
    "            SELECT '{dtitle}', '{dname}', '{dformat}', '{dspatial}', '{dpermission}', '{dpublish}', 'published', '{dtag}', '{ddesc}', '{dcat}', '{dcontact}', '{cols}', '{rows}'\n",
    "            WHERE NOT EXISTS (SELECT 1 FROM {om_dschema}.{om_dtable} WHERE data_name = '{dname}');\n",
    "            \"\"\"\n",
    "        ))\n",
    "\n",
    "        # Update data record\n",
    "        dupdate.append(dedent(\n",
    "            f\"\"\"\n",
    "            --- {dname} dataset record\n",
    "            UPDATE {om_dschema}.{om_dtable}\n",
    "            SET\n",
    "                title = '{dtitle}',\n",
    "                data_name = '{dname}',\n",
    "                \\\"format\\\" = '{dformat}',\n",
    "                is_spatial = '{dspatial}',\n",
    "                \\\"permission\\\" = '{dpermission}',\n",
    "                last_updated_date = '{dpublish}',\n",
    "                status = 'published',\n",
    "                tag = '{dtag}',\n",
    "                data_desc = '{ddesc}',\n",
    "                category = '{dcat}',\n",
    "                contact = '{dcontact}',\n",
    "                data_columns = '{cols}',\n",
    "                data_rows = '{rows}' \n",
    "            WHERE data_name = '{dname}';\n",
    "            \"\"\"\n",
    "        ))\n",
    "        \n",
    "    # Add data record\n",
    "    dinsert = ''.join(dinsert)\n",
    "    dupdate = ''.join(dupdate)\n",
    "    connection.execute(text(dinsert))\n",
    "    connection.execute(text(dupdate))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5cb5b42-6e1b-4450-bf58-31693a3664ab",
   "metadata": {},
   "source": [
    "## Add Dataset Record\n",
    "\n",
    "Query for the current dataset table or create one if it does not exist.\n",
    "\n",
    "Then add a record for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4f7f7bd9-b5f7-4837-adb4-05f4de66406c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:46:27.238287Z",
     "iopub.status.busy": "2023-06-13T23:46:27.238157Z",
     "iopub.status.idle": "2023-06-13T23:46:27.727945Z",
     "shell.execute_reply": "2023-06-13T23:46:27.727584Z"
    }
   },
   "outputs": [],
   "source": [
    "om_dstable = config['Dataset Table']\n",
    "om_dsschema = config.get('Dataset Schema', 'public')\n",
    "\n",
    "with uengine.connect() as connection:\n",
    "    \n",
    "    # Create dataset table if not exists\n",
    "    dscreate = text(dedent(\n",
    "        f\"\"\"\n",
    "        --- Dataset records table\n",
    "        CREATE TABLE IF NOT EXISTS {om_dsschema}.{om_dstable} (\n",
    "            dataset_id SERIAL PRIMARY KEY,\n",
    "            title VARCHAR UNIQUE,\n",
    "            title_abbr VARCHAR UNIQUE,\n",
    "            status VARCHAR,\n",
    "            data_id VARCHAR,\n",
    "            publish_date TIMESTAMP WITH TIME ZONE,\n",
    "            tag VARCHAR,\n",
    "            dataset_desc VARCHAR,\n",
    "            contact VARCHAR,\n",
    "            last_update_date TIMESTAMP WITH TIME ZONE,\n",
    "            permission VARCHAR\n",
    "        );\n",
    "        \"\"\"\n",
    "    ))\n",
    "    connection.execute(dscreate)\n",
    "    connection.execute(text('COMMIT;'))\n",
    "    \n",
    "    # Get data ids\n",
    "    dquery = text(\n",
    "        f\"\"\"\n",
    "        SELECT data_id, data_name FROM {om_dschema}.{om_dtable} WHERE data_name = ANY(:names);\n",
    "        \"\"\"\n",
    "    )\n",
    "    dids = pd.read_sql(dquery, uengine, params={\n",
    "        'names': [d['Name'] + f'_v{ver}' for d in config['Data']]\n",
    "    })\n",
    "    dids = ','.join(dids['data_id'].astype(str).tolist())\n",
    "    \n",
    "    # Get markdown description\n",
    "    with open(f'../README.md', 'r') as file:\n",
    "        md = file.read()\n",
    "    ddesc = re.split(r'(\\n#)', md) # split by sections\n",
    "    ddesc = [ddesc[i-1].strip() + d if i > 0 and '\\n#' == ddesc[i -1] else d for i, d in enumerate(ddesc)] # join back hashtags\n",
    "    ddesc = [d for d in ddesc if '## About' in d or '## Citation' in d] # filter for certain sections\n",
    "    ddesc = '\\n\\n'.join(ddesc)\n",
    "    ddesc = ddesc.replace('## About\\n\\n', '') # Remove about section title\n",
    "    ddesc = ddesc.replace(\"'\", \"''\") # replace single quotes with double for pg\n",
    "    \n",
    "    # Set metadata\n",
    "    dstitle = config['Title']\n",
    "    dstitle_abbr_default = ''.join(filter(str.isupper, dstitle.title())).lower()\n",
    "    dstitle_abbr = config.get('Abbreviation', dstitle_abbr_default)\n",
    "    dscontact = config.get('Contact', 'support@openmortality.org')\n",
    "    dspublish = str(datetime.now().astimezone())\n",
    "    dstag = config.get('Tag', '')\n",
    "    dspermission = config.get('Permission', 'user')\n",
    "    \n",
    "    # Add dataset record\n",
    "    dsinsert = text(dedent(\n",
    "        f\"\"\"\n",
    "        --- {dstitle_abbr} dataset record\n",
    "        INSERT INTO {om_dsschema}.{om_dstable} (title, title_abbr, status, data_id, contact, publish_date, tag, dataset_desc, \\\"permission\\\")\n",
    "        SELECT '{dstitle}', '{dstitle_abbr}', 'published', '{dids}', '{dscontact}', '{dspublish}', '{dstag}', '{ddesc}', '{dspermission}'\n",
    "        WHERE NOT EXISTS (SELECT 1 FROM {om_dsschema}.{om_dstable} WHERE title = '{dstitle}');\n",
    "        \"\"\"\n",
    "    ))\n",
    "    connection.execute(dsinsert)\n",
    "\n",
    "    # Update dataset record\n",
    "    dsupdate = text(dedent(\n",
    "        f\"\"\"\n",
    "        --- {dstitle_abbr} dataset record\n",
    "        UPDATE {om_dsschema}.{om_dstable}\n",
    "        SET\n",
    "            title = '{dstitle}',\n",
    "            title_abbr = '{dstitle_abbr}',\n",
    "            status = 'published',\n",
    "            data_id = '{dids}',\n",
    "            contact = '{dscontact}',\n",
    "            publish_date = '{dspublish}',\n",
    "            tag = '{dstag}',\n",
    "            dataset_desc = '{ddesc}',\n",
    "            \\\"permission\\\" = '{dspermission}'\n",
    "        WHERE title = '{dstitle}';\n",
    "        \"\"\"\n",
    "    ))\n",
    "    connection.execute(dsupdate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10c86675-bba3-4de3-8ecc-6eab13f2dfe3",
   "metadata": {},
   "source": [
    "## Grant Access to User\n",
    "\n",
    "Grant access to OM user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dab2dc98-b1fb-4d10-a794-006a4859243f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:46:27.730179Z",
     "iopub.status.busy": "2023-06-13T23:46:27.730012Z",
     "iopub.status.idle": "2023-06-13T23:46:27.732973Z",
     "shell.execute_reply": "2023-06-13T23:46:27.732663Z"
    }
   },
   "outputs": [],
   "source": [
    "if is_om:\n",
    "    omuser = config['Database User']\n",
    "    with uengine.connect() as connection:\n",
    "        \n",
    "        # Create grant sql\n",
    "        grantsql = ['--- Grant select on data for OM user']\n",
    "        for data in config['Data']:\n",
    "            dtable = data['Name'] + f'_v{ver}'\n",
    "            dschema = data.get('Upload Schema', 'public')\n",
    "            grantsql.append(f'GRANT SELECT ON TABLE {dschema}.{dtable} TO {omuser};')\n",
    "        grantsql = text('\\n'.join(grantsql))\n",
    "        \n",
    "        # Grant access to user for added tables\n",
    "        connection.execute(grantsql)\n",
    "        connection.execute(text('COMMIT;'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41ff54d7-4e04-4ae8-94a8-1b851eebc3d5",
   "metadata": {},
   "source": [
    "## Refresh Dataset Records View\n",
    "\n",
    "Refresh materialized view for dataset records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6d61a0bd-dbb7-4cd5-8954-bba4d57c9cb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:46:27.735064Z",
     "iopub.status.busy": "2023-06-13T23:46:27.734889Z",
     "iopub.status.idle": "2023-06-13T23:46:27.737443Z",
     "shell.execute_reply": "2023-06-13T23:46:27.737005Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_om:\n",
    "    matview = config['Dataset Refresh View']\n",
    "    with uengine.connect() as connection:\n",
    "        refreshsql = text(f'--- Refresh dataset records materialized view \\nREFRESH MATERIALIZED VIEW {matview};')\n",
    "        connection.execute(refreshsql)\n",
    "        connection.execute(text('COMMIT;'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b168e22-146f-4909-80a3-f9696f3c0ec2",
   "metadata": {},
   "source": [
    "## Save Data Records SQL\n",
    "\n",
    "Save data records sql to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "88d47cf7-8a22-4d3a-92f7-0196ae722c6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:46:27.739404Z",
     "iopub.status.busy": "2023-06-13T23:46:27.739271Z",
     "iopub.status.idle": "2023-06-13T23:46:27.742112Z",
     "shell.execute_reply": "2023-06-13T23:46:27.741792Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f'database/{abbrv}_data_v{ver}.sql', 'w') as file:\n",
    "    if is_om:\n",
    "        file.write(str(dcreate) + str(dupdate) + str(dinsert) + '\\n' + str(grantsql))\n",
    "    else:\n",
    "        file.write(str(dcreate) + str(dupdate) + str(dinsert))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "468703aa-9257-4297-8189-3f016e25b574",
   "metadata": {},
   "source": [
    "## Save Dataset Records SQL\n",
    "\n",
    "Save dataset records sql to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1f86bed4-1d66-463b-b9bf-cdf2b4f2485c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:46:27.743926Z",
     "iopub.status.busy": "2023-06-13T23:46:27.743793Z",
     "iopub.status.idle": "2023-06-13T23:46:27.746512Z",
     "shell.execute_reply": "2023-06-13T23:46:27.746164Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f'database/{abbrv}_dataset_v{ver}.sql', 'w') as file:\n",
    "    if is_om:\n",
    "        file.write(str(dscreate) + str(dsupdate) + str(dsinsert) + '\\n' + str(refreshsql))\n",
    "    else:\n",
    "        file.write(str(dscreate) + str(dsupdate) + str(dsinsert) + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eafd26f9-1d38-4654-adf1-7b988c06f543",
   "metadata": {},
   "source": [
    "# Close Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b60bf6a8-f2c7-4df6-a55e-2809950122c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T23:46:27.748469Z",
     "iopub.status.busy": "2023-06-13T23:46:27.748221Z",
     "iopub.status.idle": "2023-06-13T23:46:27.750683Z",
     "shell.execute_reply": "2023-06-13T23:46:27.750301Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "engine.dispose()\n",
    "uengine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
